{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Importing the datasets both training and test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Data/PartA/20ng_train.csv',compression = 'bz2')\n",
    "df_test = pd.read_csv('./Data/PartA/20ng_test.csv',compression = 'bz2')\n",
    "df_labels = pd.read_csv('./Data/PartA/20ng_labels.csv',compression = 'bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "0  comp.sys.ibm.pc.hardware\n",
       "1     comp.sys.mac.hardware\n",
       "2                 rec.autos\n",
       "3           rec.motorcycles\n",
       "4                 sci.crypt\n",
       "5           sci.electronics\n",
       "6    soc.religion.christian\n",
       "7        talk.religion.misc"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1.1__ : Focusing first on the training set, summarise the key features/observations\n",
    "in the data: focus on the dimensionality, data ranges, feature and class distribution and\n",
    "report anything out of the ordinary. What are the typical values of the features like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This is the dataframe for overall information about the training set data. The training set consists of 5648 different documents with total of 1001 unique words and has 8 different class labels._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5648, 1001)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_described = df_train.describe()\n",
    "df_train_described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Class 7, talk.religion.misc, has less data provided than all other classes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class_counts = df_train[\"class\"].value_counts()\n",
    "df_train_class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The typical values (mean) of the features like for each class label is calculated below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tfidf_classes = [[0] * 1000]*8\n",
    "for index, row in df_train.iterrows():\n",
    "    list_of_tfidf_classes[int(row['class'])] = list_of_tfidf_classes[int(row['class'])] + row[:-1]\n",
    "for x in range(0,8):\n",
    "    list_of_tfidf_classes[x] = list_of_tfidf_classes[x]/df_train_class_counts[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tfidf_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The words mostly have the same tf-idf value; this can be understood by taking the standard deviation of the means of each unique word, which is low._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_described.iloc[1,:].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1.2__ : Looking now at the Testing set, how does it compare with the Training\n",
    "Set (in terms of sizes and feature-distributions) and what could be the repurcussions of\n",
    "this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__There is a split of 75% training set to 25% test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>3.345194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>0.021777</td>\n",
       "      <td>0.032393</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.033441</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.037389</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.043570</td>\n",
       "      <td>2.208286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.864159</td>\n",
       "      <td>0.469412</td>\n",
       "      <td>0.337561</td>\n",
       "      <td>0.620254</td>\n",
       "      <td>0.310053</td>\n",
       "      <td>0.504324</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.387412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490894</td>\n",
       "      <td>0.481298</td>\n",
       "      <td>0.434553</td>\n",
       "      <td>0.543384</td>\n",
       "      <td>0.470697</td>\n",
       "      <td>0.566179</td>\n",
       "      <td>0.537827</td>\n",
       "      <td>0.532047</td>\n",
       "      <td>0.590114</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                __      ability         able           ac       accept  \\\n",
       "count  1883.000000  1883.000000  1883.000000  1883.000000  1883.000000   \n",
       "mean      0.002292     0.002168     0.007335     0.002817     0.002701   \n",
       "std       0.032391     0.021397     0.034312     0.032169     0.021777   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.864159     0.469412     0.337561     0.620254     0.310053   \n",
       "\n",
       "            access    according      account          act       action  ...  \\\n",
       "count  1883.000000  1883.000000  1883.000000  1883.000000  1883.000000  ...   \n",
       "mean      0.004449     0.003012     0.001716     0.001886     0.001745  ...   \n",
       "std       0.032393     0.026133     0.022855     0.019504     0.018376  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.504324     0.420903     0.632166     0.336667     0.387412  ...   \n",
       "\n",
       "             worth       wouldn        write      written        wrong  \\\n",
       "count  1883.000000  1883.000000  1883.000000  1883.000000  1883.000000   \n",
       "mean      0.003018     0.005356     0.003746     0.003812     0.007960   \n",
       "std       0.026231     0.033441     0.028779     0.032836     0.039182   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.490894     0.481298     0.434553     0.543384     0.470697   \n",
       "\n",
       "             wrote         year        years          yes        class  \n",
       "count  1883.000000  1883.000000  1883.000000  1883.000000  1883.000000  \n",
       "mean      0.001970     0.006214     0.008706     0.009449     3.345194  \n",
       "std       0.020613     0.037389     0.041551     0.043570     2.208286  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     3.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     5.000000  \n",
       "max       0.566179     0.537827     0.532047     0.590114     7.000000  \n",
       "\n",
       "[8 rows x 1001 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns respectively of training set: 5648, 1001\n",
      "Training set class distribution:\n",
      "6    748\n",
      "3    747\n",
      "4    743\n",
      "2    742\n",
      "5    738\n",
      "0    737\n",
      "1    722\n",
      "7    471\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Number of rows and columns respectively of test set: 1883, 1001\n",
      "Test set class distribution:\n",
      "6    249\n",
      "3    249\n",
      "4    248\n",
      "2    248\n",
      "5    246\n",
      "0    245\n",
      "1    241\n",
      "7    157\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows and columns respectively of training set: ' \n",
    "      + str(df_train.shape[0]) + ', ' + str(df_train.shape[1]))\n",
    "\n",
    "print('Training set class distribution:')\n",
    "print(df_train[\"class\"].value_counts())\n",
    "print()\n",
    "\n",
    "print('Number of rows and columns respectively of test set: ' \n",
    "      + str(df_test.shape[0]) + ', ' + str(df_test.shape[1]))\n",
    "\n",
    "print('Test set class distribution:')\n",
    "print(df_test[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1.3__ : Why do you think it is useful to consider TF-IDF weights as opposed to\n",
    "just the frequency of times a word appears in a document as a feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TF-IDF will create weights according how important a word is in a document. For example if the word is used very frequently, like stop words , the idf value will be close to 0. Thus TF-IDF somehow eliminates/clears not 'important' words from the feature vectors. For example, considering the stop words might be inrelevant and computations can be costly._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.1 :__ The K-Means algorithm is non-deterministic. Explain why this is, and\n",
    "how the final model is selected in the SKLearn implementation of KMeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The initial selection of the cluster centers might affect the result in the end. Even though the data points are the same, the algorithm causes the non-determinisim. The test point might be classified differently acording to the initial cluster centers. We will not explicitly select the cluster centres in the SKLearn model; the model itself will select the initial cluster centers which speeds up the convergence of the algorithm._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.2:__ One of the parameters we need to specify when using k-means is the number\n",
    "of clusters. What is a reasonable number for this problem and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_By visualising the data, we will decide number of clusters we would like to use. The outliers in the data will be either removed or transformed. However it is impossible to come up with a graph for more than 3 dimensions. In this case we can use SSE(sum squared error) to decide which k value will be optimal. Example code can be seen below:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32840.52090499835,\n",
       " 12011.220991420803,\n",
       " 8263.254576986266,\n",
       " 6608.1852836296985,\n",
       " 6224.152404490892,\n",
       " 5841.347863264131,\n",
       " 5469.012993329456,\n",
       " 5175.799878800897,\n",
       " 5160.044981727505,\n",
       " 5145.941835367454,\n",
       " 5135.804262786552,\n",
       " 5120.659758560258,\n",
       " 5105.5044275561995,\n",
       " 5099.181663921659]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(df_train)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "Sum_of_squared_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.3:__ We will use the Adjusted Mutual Information (AMI) i.e. adjusted_mutual\n",
    "_info_score between the clusters and the true (known) labels to quantify the performance of the clustering. Give an expression for the MI in terms of entropy. In short,\n",
    "describe what the MI measures about two variables, why this is applicable here and why\n",
    "it might be difficult to use in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume two label assignments (of the same N objects), U and V. Their entropy is the amount of uncertainty for a partition set, defined by:\n",
    "\n",
    "\\begin{align}\n",
    "H(U) = - \\sum_{i=1}^{|U|}P(i)\\log(P(i))\n",
    "\\end{align}\n",
    "\n",
    "where P(i) is the probability that an object picked at random from U falls into class Ui and same for P'(j).\n",
    "\n",
    "\\begin{align}\n",
    "H(V) = - \\sum_{j=1}^{|V|}P'(j)\\log(P'(j))\n",
    "\\end{align}\n",
    "\n",
    "The Mutual Information is given in terms of entrophy can be seen below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{MI}(U, V) = \\sum_{i=1}^{|U|}\\sum_{j=1}^{|V|}P(i, j)\\log\\left(\\frac{P(i,j)}{P(i)P'(j)}\\right)\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\\begin{align}\n",
    "P(i, j) = |U_i \\cap V_j| / N\n",
    "\\end{align}\n",
    "\n",
    "is the probability that an object picked at random falls into both classes Ui and Vj.\n",
    "\n",
    "Also there is another version without the probabilities:\n",
    "\\begin{align}\n",
    "\\text{MI}(U, V) = \\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i \\cap V_j|}{N}\\log\\left(\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}\\right)\n",
    "\\end{align}\n",
    "\n",
    "MI is a measure which tells us how much one variable tells us other variable (it is somehow related to the covariance). __\"Covariance is only able to takes into account linear relationships but the MI can also handle non-linear relationships.\"__ \"Mutual information calculates the statistical dependence between two variables and is the name given to information gain when applied to variable selection.\" (https://machinelearningmastery.com/information-gain-and-mutual-information/)\n",
    "\n",
    "It might be hard because there will be many variables, we would have to do \n",
    "\\begin{align}\n",
    "\\binom{N}{2}\n",
    "\\end{align}\n",
    "many computations, where N is the number of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.4:__ Fit K-Means objects with n_clusters ranging from 2 to 12. Set the\n",
    "random seed to 1000 and the number of initialisations to 50, but leave all other values\n",
    "at default. For each fit compute the adjusted mutual information (there is an SKLearn\n",
    "function for that). Set average_method='max' . Plot the AMI scores against the number\n",
    "of clusters (as a line plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI = []\n",
    "\n",
    "df_train_without_classes = df_train.drop('class', axis = 1)\n",
    "df_test_without_classes = df_test.drop('class', axis = 1)\n",
    "\n",
    "for k in range(2,13):\n",
    "    \n",
    "    km = KMeans(n_clusters=k, random_state=1000, n_init = 50)\n",
    "    km = km.fit(df_train_without_classes)\n",
    "    y_pred = km.predict(df_test_without_classes)\n",
    "\n",
    "    AMI.append(adjusted_mutual_info_score(df_test['class'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09467890113466797,\n",
       " 0.1950356379915207,\n",
       " 0.24891808033912957,\n",
       " 0.2288771399046942,\n",
       " 0.2726797810438812,\n",
       " 0.2911458052678768,\n",
       " 0.32015410354365886,\n",
       " 0.24870198923466513,\n",
       " 0.31256372069963395,\n",
       " 0.2943868732717312,\n",
       " 0.29197266625025264]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4cb1f78b00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(x=range(2,13), y=AMI)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://math.stackexchange.com/questions/438078/mutual-information-for-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.5:__ Discuss any trends and interesting aspects which emerge from the plot.\n",
    "Does this follow from your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO: Enter the answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.6:__ Let us investigate the case with four (4) clusters in some more detail.\n",
    "Using seaborn's countplot function, plot a bar-chart of the number of data-points with a\n",
    "particular class (encoded by colour) assigned to each cluster centre (encoded by position\n",
    "on the plot's x-axis). As part of the cluster labels, include the total number of data-points\n",
    "assigned to that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f688bd6d0f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_without_classes = df_train.drop('class', axis = 1)\n",
    "\n",
    "km_histogram = KMeans(n_clusters=4, random_state=1000, n_init = 50)\n",
    "km_histogram = km_histogram.fit(df_train_without_classes)\n",
    "\n",
    "\n",
    "ax_new = sns.countplot(x=km_histogram.labels_, hue = \"class\", data=df_train)\n",
    "ax_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2.7:__ How does the clustering in Question2:(f) align with the true class labels?\n",
    "Does it conform to your observations in Q 2(e)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels according to the same type of subjects, like computers, are clustered together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.1:__ What is the F1-score, and why is it preferable to accuracy in our problem?\n",
    "How does the macro-average work to extend the score to multi-class classi\u001c",
    "cation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_F1 score is a measurement which indicates whether the classified data is correct or not. It uses two measures which are recall and precission to find the F1 score. \"Micro- and macro-averages (for whatever metric) will compute slightly different things, and thus their interpretation differs. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\" (https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.2:__ As always we start with a simple baseline classi\u001c",
    "er. De\u001c",
    "ne such a classi\u001c",
    "er\n",
    "(indicating why you chose it) and report its performance on the Test set. Use the `macro'\n",
    "average for the f1_score ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02909432191459409"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_prediction = [2]*1883\n",
    "f1_score(df_test['class'], baseline_prediction, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.3:__ We will now train a LogisticRegression Classi\u001c",
    "er from SKLearn. By\n",
    "referring to the documentation, explain how the Logistic Regression model can be applied\n",
    "to classify multi-class labels as in our case. Hint: Limit your explanation to methods we\n",
    "discussed in the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: EXPLAIN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.4:__ Train a Logistic Regressor on the training data. Set `solver=lbfgs`, \n",
    "`multi_class=multinomial` and random_state=0 . Use the Cross-Validation object you\n",
    "created and report the average validation-set F1-score as well as the standard deviation.\n",
    "Comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class= 'multinomial', solver = 'lbfgs',\n",
    "                       random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr = df_train.drop('class', axis = 1).to_numpy()\n",
    "y_train_lr = df_train['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6625495496128986\n",
      "Standard deviation: 2.134835443282763\n",
      "0.6804918899173111\n",
      "Standard deviation: 2.0545216449687045\n",
      "0.6815497804608959\n",
      "Standard deviation: 2.118289090776395\n",
      "0.6425966123149198\n",
      "Standard deviation: 2.1549761016285855\n",
      "0.685255241774714\n",
      "Standard deviation: 2.0979088895436004\n",
      "0.6942403363745525\n",
      "Standard deviation: 2.140068205865807\n",
      "0.6667317607628829\n",
      "Standard deviation: 2.1692819829158676\n",
      "0.6569984934920572\n",
      "Standard deviation: 2.141263620051749\n",
      "0.6582862150524074\n",
      "Standard deviation: 2.1473693936241536\n",
      "0.6510492803037036\n",
      "Standard deviation: 2.116099532381271\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skf.split(X_train_lr, y_train_lr):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_train_lr[train_index], X_train_lr[test_index]\n",
    "    y_train, y_test = y_train_lr[train_index], y_train_lr[test_index]\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(f1_score(y_test, y_pred, average='macro'))\n",
    "    print('Standard deviation: ' + str(y_pred.std()))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO : COMMENT ON THE RESULTS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.5:__ We will now optimise the Regularisation parameter C using cross-validation.\n",
    "Train a logistic regressor for di\u001berent values of C : in each case, evaluate the F1 score on\n",
    "the training and validation portion of the fold. That is, for each value of C you must\n",
    "provide the training set and validation-set scores per fold and then compute (and store)\n",
    "the average of both over all folds. Finally plot the (average) training and validation-set\n",
    "scores as a function of C . Hint: Use a logarithmic scale for C , spanning 19 samples\n",
    "between 10^âˆ’4 to 10^5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = np.logspace(start = -4, stop= 5, num = 19, base = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_f1score_average = []\n",
    "\n",
    "for c in log_list:\n",
    "    \n",
    "    lr_with_C = LogisticRegression(multi_class= 'multinomial', \n",
    "                solver = 'lbfgs', random_state = 0, C = float(c))\n",
    "    sum = 0\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train_lr, y_train_lr):\n",
    "    \n",
    "        X_train, X_test = X_train_lr[train_index], X_train_lr[test_index]\n",
    "        y_train, y_test = y_train_lr[train_index], y_train_lr[test_index]\n",
    "              \n",
    "        lr_with_C.fit(X_train, y_train)\n",
    "        y_pred = lr_with_C.predict(X_test)\n",
    "        sum = sum + f1_score(y_test, y_pred, average='micro')\n",
    "        \n",
    "    list_of_f1score_average.append(sum/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19319409126669226,\n",
       " 0.3087628112860118,\n",
       " 0.47978785498801846,\n",
       " 0.6127227939752368,\n",
       " 0.6492060466563897,\n",
       " 0.6568161761397191,\n",
       " 0.6669073387450754,\n",
       " 0.6851531188184111,\n",
       " 0.681095110717517,\n",
       " 0.6754297160335946,\n",
       " 0.6598512811909334,\n",
       " 0.6426910549961333,\n",
       " 0.6333065882805785,\n",
       " 0.6361550906326925,\n",
       " 0.63614912146366,\n",
       " 0.6345398466531653,\n",
       " 0.6334741026838027,\n",
       " 0.6345517698146561,\n",
       " 0.632952194716192]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_f1score_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 3.16227766e-04, 1.00000000e-03, 3.16227766e-03,\n",
       "       1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,\n",
       "       1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,\n",
       "       1.00000000e+02, 3.16227766e+02, 1.00000000e+03, 3.16227766e+03,\n",
       "       1.00000000e+04, 3.16227766e+04, 1.00000000e+05])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a2e31b898>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(x=log_list, y=list_of_f1score_average)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.6:__ What is the optimal value of C (and the corresponding score)? How did\n",
    "you choose this value? By making reference to the e\u001bect of the regularisation parameter\n",
    "C on the optimisation, explain what is happening in your plot from Question 3:(e) Hint:\n",
    "Refer to the documentation for C in the LogisticRegression page on SKLearn ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_According to what I have calculated, as it can seen above, 3.16e-1 is the best hyper parameter C amongs other 18 choices._ __TODO:WRITE MORE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3.7__ Finally, report the score of the best model on the test-set, after retraining\n",
    "on the entire training set (that is drop the folds). Hint: You may need to set max_iter\n",
    "= 200 . Comment brie\u001d",
    "y on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lr = df_test.drop('class', axis = 1)\n",
    "y_test_lr = df_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression(multi_class= 'multinomial', \n",
    "                solver = 'lbfgs', random_state = 0, \n",
    "                C = 3.16227766e-01, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6649874691737969\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(X_train_lr, y_train_lr)\n",
    "y_predicted= lr_final.predict(X_test_lr)\n",
    "print(f1_score(y_test_lr, y_predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
